\documentclass{exam}
\usepackage{pgfplots}
\usepackage{filecontents}
\usepackage{siunitx}
\pgfplotsset{compat=1.15}

\firstpageheader{EE4204}{Socket Programming Assignment Report}{\today}
\runningheader{EE4204}{Socket Programming Assignment Report (Continued)}{\today}
\footer{}{\thepage}{}

\begin{document}
Assumptions:

The amount of computational resource available to the C programs remains stable. 127.0.0.1 is the most common IPv4 loopback address, therefore everything happens internally, the data does not travel through external media such as cables or electromagnetic waves and the only constraint is the local resources. Besides the processor speed, the number of other programs that are open and whether the programs are in a virtual machine may also affect the values recorded.

Results:

For 1 and 2, I chose to plot from \SI{0}{\percent} to \SI{99}{\percent}. I chose 1000 as my data length.

For data unit size, 235 is the lowest value I could use and not encounter frequent errors. Therefore I chose to plot from 235 to 49735, with the step being 500. I chose \SI{50}{\percent} as the other error probability constant.

Comparison:

From the first two graphs plotted against error probability we can see that the higher the error probability, the more times data has to be re-transmitted, resulting in more time spent to successfully sent the same amount of data and therefore lower throughput. The same trend  can be seen on the graphs plotted against data unit size. Although the general shape does not change, the scale on the y-axis changes to reflect the trend.

From the four graphs plotted against data unit size, it can be seen that throughput increases gradually as data unit size increases. On the other hand, while there is a sharp decrease in transfer time for very small data unit sizes, very quickly the transfer time stabilises and any further impact is negligible. This is because initially the protocol overhead of TCP (known to be significantly higher than that of UDP) is much closer to the data unit size (or even higher). As the data unit size increases, the size of the protocol overhead becomes negligible.

\begin{questions}

\question Transfer time vs error probability 

\begin{tikzpicture}
\begin{axis}[
xlabel = {error probability / \si{\percent}},
ylabel = {transfer time / \si{\milli\second} }
]
\addplot table [x=error_p, y=ti, col sep=comma] {epTime.csv};
\end{axis}
\end{tikzpicture}


\question Throughput vs error probability

\begin{tikzpicture}
\begin{axis}[
xlabel = {error probability / \si{\percent}},
ylabel = {throughput / \si{kBps} }
]
\addplot table [x=error_p, y=rt, col sep=comma] {epRate.csv};
\end{axis}
\end{tikzpicture}

\newpage

\question

\begin{parts}
\part Transfer time vs data unit size (error probability = 0)

\begin{tikzpicture}
\begin{axis}[
xlabel = {data unit size / \si{byte}},
ylabel = {transfer time / \si{\milli\second} }
]
\addplot table [x=data_len, y=ti, col sep=comma] {dusTime-err0.csv};
\end{axis}
\end{tikzpicture}

\part Transfer time vs data unit size (error probability = 50)

\begin{tikzpicture}
\begin{axis}[
xlabel = {data unit size / \si{byte}},
ylabel = {transfer time / \si{\milli\second} }
]
\addplot table [x=data_len, y=ti, col sep=comma] {dusTime-err50.csv};
\end{axis}
\end{tikzpicture}
\end{parts}

\newpage

\question

\begin{parts}
\part Throughput vs data unit size (error probability = 0)

\begin{tikzpicture}
\begin{axis}[
xlabel = {data unit size / \si{byte}},
ylabel = {throughput / \si{kBps} }
]
\addplot table [x=data_len, y=rt, col sep=comma] {dusRate-err0.csv};
\end{axis}
\end{tikzpicture}

\part Throughput vs data unit size (error probability = 50)

\begin{tikzpicture}
\begin{axis}[
xlabel = {data unit size / \si{byte}},
ylabel = {throughput / \si{kBps} }
]
\addplot table [x=data_len, y=rt, col sep=comma] {dusRate-err50.csv};
\end{axis}
\end{tikzpicture}
\end{parts}


\end{questions}
\end{document}